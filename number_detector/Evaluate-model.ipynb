{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a225e506",
   "metadata": {},
   "source": [
    "## Evalutate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e6936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, InputLayer\n",
    "from tensorflow.keras import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657c8c0d",
   "metadata": {},
   "source": [
    "## Restore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5dbff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN_2_model(settings):\n",
    "    # this has 34,826 training parameters -> ~411kB\n",
    "    k1 = settings['conv2d_1']['kernel_size']\n",
    "    n1 = settings['conv2d_1']['n_nodes']\n",
    "    k2 = settings['conv2d_2']['kernel_size']\n",
    "    n2 = settings['conv2d_2']['n_nodes']\n",
    "    model = Sequential(\n",
    "        [\n",
    "            InputLayer(input_shape=(28, 28, 1)),\n",
    "            Conv2D(n1, kernel_size=(k1, k1), activation=\"relu\"),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(n2, kernel_size=(k2, k2), activation=\"relu\"),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Flatten(),\n",
    "            Dropout(0.5),\n",
    "            Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "settings = {\n",
    "        \"CNN_2\": { # 34,826 parameters\n",
    "            'conv2d_1': {\n",
    "                'kernel_size': 3,\n",
    "                'n_nodes': 32\n",
    "            },\n",
    "            'conv2d_2': {\n",
    "                'kernel_size': 3,\n",
    "                'n_nodes': 64\n",
    "            }, \n",
    "        },\n",
    "        \"CNN_3\": { # 12,810 parameters\n",
    "            'conv2d_1': {\n",
    "                'kernel_size': 3,\n",
    "                'n_nodes': 16\n",
    "            },\n",
    "            'conv2d_2': {\n",
    "                'kernel_size': 3,\n",
    "                'n_nodes': 32\n",
    "            },\n",
    "        },\n",
    "         \"CNN_4\": { # 18,378 parameters\n",
    "            'conv2d_1': {\n",
    "                'kernel_size': 5,\n",
    "                'n_nodes': 16\n",
    "            },\n",
    "            'conv2d_2': {\n",
    "                'kernel_size': 5,\n",
    "                'n_nodes': 32\n",
    "            }, \n",
    "        },\n",
    "    }\n",
    "\n",
    "def build_NN_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(Dense(32, activation='sigmoid'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'models/CNN_4_74k/'\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_CNN_2_model(settings['CNN_4'])\n",
    "#model = build_NN_model()\n",
    "model.load_weights(latest)\n",
    "print(\"weights restored!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20d076",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pic = np.random.random((28, 28))\n",
    "plt.imshow(dummy_pic, cmap='gray', vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55932f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pic = dummy_pic.reshape(1, 28, 28, 1)\n",
    "np.argmax(model.predict(dummy_pic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9653d91",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(mnist_path):\n",
    "    labels = []\n",
    "    digits = []\n",
    "    with open(mnist_path) as f:\n",
    "        f.readline()\n",
    "        for line in f.readlines():\n",
    "            data = line.split(\",\")\n",
    "            label = int(data[0])\n",
    "            img = np.array(list(map(int, data[1:]))).reshape((28, 28))\n",
    "            labels.append(label)\n",
    "            digits.append(img)\n",
    "    labels = np.array(labels)\n",
    "    digits = np.array(digits)\n",
    "    return digits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415aec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../datasets\"\n",
    "dataset = \"74k\" # MNIST font 74k combined\n",
    "train_path = os.path.join(input_dir, dataset + \"_train.csv\")\n",
    "test_path = os.path.join(input_dir, dataset + \"_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ea318",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading data ...\")\n",
    "train_digits, train_labels = load_mnist(train_path)\n",
    "test_digits, test_labels = load_mnist(test_path)\n",
    "print(\"data loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d01ce",
   "metadata": {},
   "source": [
    "## Prep for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_digits.astype('float32')/255\n",
    "y_train = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "\n",
    "y_test = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "x_test = test_digits.astype('float32')/255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad89d1b",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test evaluation\")\n",
    "print(\"accuracy: {:5.2f}%\".format(100 * acc))\n",
    "print(\"loss:     {:5.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ba3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_train, y_train, verbose=2)\n",
    "print(\"test evaluation\")\n",
    "print(\"accuracy: {:5.2f}%\".format(100 * acc))\n",
    "print(\"loss:     {:5.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f21011",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c597455",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([np.argmax(y) for y in model.predict(x_test, verbose=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = np.array([np.argmax(y) for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3962bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(y_pred, y_labels, num_classes=10)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a771b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(cm)\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm[0])):\n",
    "        text = ax.text(j, i, cm[i, j].numpy(), ha=\"center\", va=\"center\", color=\"w\")\n",
    "ax.set_xlabel('predicted classes')\n",
    "ax.set_ylabel('real classes')\n",
    "ax.set_xticks(range(10));\n",
    "ax.set_yticks(range(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b99f9",
   "metadata": {},
   "source": [
    "### Plot incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc11387",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dee84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 3\n",
    "fig, axes = plt.subplots(nrow, 10, figsize=(12, 5))\n",
    "for j in range(10):\n",
    "    idxs_wrong = np.logical_and(y_pred == j, y_pred != y_labels)\n",
    "    idxs_j = np.arange(len(y_pred))[idxs_wrong]\n",
    "    labels_j = y_pred[idxs_wrong]\n",
    "    idxs = np.random.choice(range(len(labels_j)), size=min(len(labels_j), nrow), replace=False)\n",
    "    for i in range(min(len(labels_j), nrow)):\n",
    "        ax = axes[i][j]\n",
    "        ax.imshow(x_data[idxs_j[i]], cmap='gray', vmin=0, vmax=1)\n",
    "        #ax.axis('off')\n",
    "        ax.set_xlabel(y_labels[idxs_j[i]])\n",
    "        ax.get_xaxis().set_ticklabels([])\n",
    "        ax.get_yaxis().set_ticklabels([])\n",
    "    axes[0][j].set_title(str(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e26a4",
   "metadata": {},
   "source": [
    "## Plot intermediate layers - Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad7bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 0\n",
    "intermediate_model = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.layers[layer_idx].output\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059780fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intermediate_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1800\n",
    "plt.imshow(x_train[idx]);\n",
    "plt.title(\"label: {:}\".format(train_labels[idx]));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ca042",
   "metadata": {},
   "source": [
    "Plot features for this input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = intermediate_model.predict(np.array([x_train[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8114f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = features.shape[-1]\n",
    "ncol = 10;\n",
    "nrow = int(np.ceil(num_features/ncol))\n",
    "\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(14, num_features/5))\n",
    "for idx in range(num_features):\n",
    "    i, j = idx//ncol, idx % ncol\n",
    "    ax = axes[i][j]\n",
    "    ax.axis('off')\n",
    "    ax.imshow(features[0, :, :, idx])\n",
    "for idx in range(num_features, ncol*nrow):\n",
    "    i, j = idx//ncol, idx % ncol\n",
    "    ax = axes[i][j]\n",
    "    ax.axis('off')\n",
    "axes[0][int(ncol//2)-1].set_title(\"{:d} features for layer {:d}\".format(num_features, layer_idx));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e135da",
   "metadata": {},
   "source": [
    "plot kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kernels = model.layers[layer_idx].kernel.shape[-1]\n",
    "ncol = 10;\n",
    "nrow = int(np.ceil(num_features/ncol))\n",
    "\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(14, n_kernels/5))\n",
    "for idx in range(n_kernels):\n",
    "    i, j = idx//ncol, idx % ncol\n",
    "    ax = axes[i][j]\n",
    "    ax.axis('off')\n",
    "    kernel = model.layers[layer_idx].kernel[:, :, :, idx]\n",
    "    ax.imshow(kernel)\n",
    "for idx in range(n_kernels, ncol*nrow):\n",
    "    i, j = idx//ncol, idx % ncol\n",
    "    ax = axes[i][j]\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7b3ff",
   "metadata": {},
   "source": [
    "## Plot intermediate layers - Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 6\n",
    "num_features = 32\n",
    "n_slice = 1\n",
    "input_shape = (4, 4, 32, 10) # (4, 4, 32, 10)  (28, 28, 32)\n",
    "weights = model.layers[layer_idx].weights[0].numpy().reshape(input_shape)\n",
    "biases =  model.layers[layer_idx].weights[1]\n",
    "\n",
    "ncol = 10;\n",
    "nrow = int(np.ceil(num_features/ncol))\n",
    "fig, axes = plt.subplots(nrow, ncol, figsize=(14, num_features/5))\n",
    "for idx in range(num_features):\n",
    "    i, j = idx//ncol, idx % ncol\n",
    "    ax = axes[i][j]\n",
    "    ax.axis('off')\n",
    "    ax.imshow(weights[:, :, idx, n_slice])\n",
    "for idx in range(num_features, ncol*nrow):\n",
    "    i, j = idx//ncol, idx % ncol\n",
    "    ax = axes[i][j]\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab21eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
